{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9dcc75",
   "metadata": {},
   "source": [
    "# AI Diet Tracker - Model Training on Google Colab\n",
    "\n",
    "Train a ResNet-50 food classifier on Food-101 dataset using **free GPU**.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Enable GPU**: Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ **T4 GPU**\n",
    "2. **Run all cells** (Runtime â†’ Run all)\n",
    "3. **Download trained model** at the end\n",
    "4. Upload `food_classifier.pth` to your backend `models/` folder\n",
    "\n",
    "**Training time:** ~30-40 minutes on free GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5d0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install torch torchvision tqdm datasets pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86a527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e883a4d",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7493730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training config\n",
    "EPOCHS = 10  # Reduce to 5 for faster training\n",
    "BATCH_SIZE = 64  # GPU can handle larger batches\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 101  # Food-101 has 101 food categories\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7b1daf",
   "metadata": {},
   "source": [
    "## Download Food-101 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transforms (data augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Validation transforms (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "print(\"Downloading Food-101 dataset... (this takes 5-10 minutes on first run)\")\n",
    "train_dataset = datasets.Food101(\n",
    "    root='./data',\n",
    "    split='train',\n",
    "    transform=train_transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_dataset = datasets.Food101(\n",
    "    root='./data',\n",
    "    split='test',\n",
    "    transform=val_transform,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"âœ… Training samples: {len(train_dataset):,}\")\n",
    "print(f\"âœ… Test samples: {len(test_dataset):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda15c6",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7842d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FoodClassifier(nn.Module):\n",
    "    \"\"\"ResNet-50 fine-tuned for food classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=101):\n",
    "        super().__init__()\n",
    "        # Load pretrained ResNet-50\n",
    "        self.backbone = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Replace final FC layer\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(in_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = FoodClassifier(num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "print(f\"âœ… Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e4a1a",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e47c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress = tqdm(loader, desc='Training')\n",
    "    for images, labels in progress:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        progress.set_postfix(\n",
    "            loss=f\"{loss.item():.4f}\",\n",
    "            acc=f\"{100.0 * correct / total:.2f}%\"\n",
    "        )\n",
    "    \n",
    "    return running_loss / len(loader), 100.0 * correct / total\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / len(loader), 100.0 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_accuracy = 0.0\n",
    "training_history = []\n",
    "\n",
    "print(f\"\\nðŸš€ Starting training for {EPOCHS} epochs...\\n\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Epoch {epoch + 1} Results:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"  Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    training_history.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'val_acc': val_acc,\n",
    "        'time_seconds': epoch_time,\n",
    "    })\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        print(f\"  âœ… New best model! (Val Acc: {val_acc:.2f}%)\")\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(f\"ðŸŽ‰ Training Complete!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5033956",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Food-101 class names\n",
    "FOOD101_CLASSES = [\n",
    "    \"apple_pie\", \"baby_back_ribs\", \"baklava\", \"beef_carpaccio\", \"beef_tartare\",\n",
    "    \"beet_salad\", \"beignets\", \"bibimbap\", \"bread_pudding\", \"breakfast_burrito\",\n",
    "    \"bruschetta\", \"caesar_salad\", \"cannoli\", \"caprese_salad\", \"carrot_cake\",\n",
    "    \"ceviche\", \"cheese_plate\", \"cheesecake\", \"chicken_curry\", \"chicken_quesadilla\",\n",
    "    \"chicken_wings\", \"chocolate_cake\", \"chocolate_mousse\", \"churros\", \"clam_chowder\",\n",
    "    \"club_sandwich\", \"crab_cakes\", \"creme_brulee\", \"croque_madame\", \"cup_cakes\",\n",
    "    \"deviled_eggs\", \"donuts\", \"dumplings\", \"edamame\", \"eggs_benedict\",\n",
    "    \"escargots\", \"falafel\", \"filet_mignon\", \"fish_and_chips\", \"foie_gras\",\n",
    "    \"french_fries\", \"french_onion_soup\", \"french_toast\", \"fried_calamari\", \"fried_rice\",\n",
    "    \"frozen_yogurt\", \"garlic_bread\", \"gnocchi\", \"greek_salad\", \"grilled_cheese_sandwich\",\n",
    "    \"grilled_salmon\", \"guacamole\", \"gyoza\", \"hamburger\", \"hot_and_sour_soup\",\n",
    "    \"hot_dog\", \"huevos_rancheros\", \"hummus\", \"ice_cream\", \"lasagna\",\n",
    "    \"lobster_bisque\", \"lobster_roll_sandwich\", \"macaroni_and_cheese\", \"macarons\", \"miso_soup\",\n",
    "    \"mussels\", \"nachos\", \"omelette\", \"onion_rings\", \"oysters\",\n",
    "    \"pad_thai\", \"paella\", \"pancakes\", \"panna_cotta\", \"peking_duck\",\n",
    "    \"pho\", \"pizza\", \"pork_chop\", \"poutine\", \"prime_rib\",\n",
    "    \"pulled_pork_sandwich\", \"ramen\", \"ravioli\", \"red_velvet_cake\", \"risotto\",\n",
    "    \"samosa\", \"sashimi\", \"scallops\", \"seaweed_salad\", \"shrimp_and_grits\",\n",
    "    \"spaghetti_bolognese\", \"spaghetti_carbonara\", \"spring_rolls\", \"steak\", \"strawberry_shortcake\",\n",
    "    \"sushi\", \"tacos\", \"takoyaki\", \"tiramisu\", \"tuna_tartare\", \"waffles\",\n",
    "]\n",
    "\n",
    "# Save checkpoint\n",
    "checkpoint = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'class_names': FOOD101_CLASSES,\n",
    "    'accuracy': best_accuracy,\n",
    "    'epochs_trained': EPOCHS,\n",
    "    'training_history': training_history,\n",
    "    'trained_at': datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'food_classifier.pth')\n",
    "print(f\"âœ… Model saved to food_classifier.pth\")\n",
    "\n",
    "# Save training report\n",
    "report = {\n",
    "    'completed_at': datetime.now().isoformat(),\n",
    "    'best_accuracy': best_accuracy,\n",
    "    'total_epochs': EPOCHS,\n",
    "    'history': training_history,\n",
    "}\n",
    "\n",
    "with open('training_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Training report saved to training_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a878a",
   "metadata": {},
   "source": [
    "## Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"ðŸ“¥ Downloading trained model...\")\n",
    "files.download('food_classifier.pth')\n",
    "files.download('training_report.json')\n",
    "\n",
    "print(\"\\nâœ… Downloaded! Upload food_classifier.pth to:\")\n",
    "print(\"   /Users/amsan/app2026/backend/models/food_classifier.pth\")\n",
    "print(\"\\nThen in .env, set:\")\n",
    "print(\"   USE_CUSTOM_MODEL=true\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
